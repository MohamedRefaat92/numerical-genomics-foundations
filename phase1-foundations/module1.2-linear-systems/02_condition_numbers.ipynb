{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02: Condition Numbers\n",
    "\n",
    "**Module 1.2: Linear Systems & Least Squares**\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "1. Understand what condition numbers measure\n",
    "2. Compute condition numbers using SVD\n",
    "3. See why $\\kappa(X^\\top X) = \\kappa(X)^2$ is dangerous\n",
    "4. Diagnose ill-conditioned problems in genomics\n",
    "\n",
    "## Resources\n",
    "- Solomon, *Numerical Algorithms*, §4.3\n",
    "- Cohen, *Practical Linear Algebra*, Chapter 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(42)\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. What is a Condition Number?\n",
    "\n",
    "The **condition number** $\\kappa(A)$ measures how sensitive the solution of $Ax = b$ is to small changes in the input.\n",
    "\n",
    "$$\\kappa(A) = \\|A\\| \\cdot \\|A^{-1}\\| = \\frac{\\sigma_{\\max}}{\\sigma_{\\min}}$$\n",
    "\n",
    "Where $\\sigma_{\\max}$ and $\\sigma_{\\min}$ are the largest and smallest singular values.\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "| $\\kappa(A)$ | Status | Meaning |\n",
    "|-------------|--------|--------|\n",
    "| $\\approx 1$ | Well-conditioned | Small input changes → small output changes |\n",
    "| $10^6$ | Ill-conditioned | Small input changes → large output changes |\n",
    "| $\\infty$ | Singular | No unique solution |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_condition_number(A):\n",
    "    \"\"\"Compute condition number using SVD.\"\"\"\n",
    "    U, S, Vh = torch.linalg.svd(A)\n",
    "    \n",
    "    sigma_max = S[0].item()\n",
    "    sigma_min = S[-1].item()\n",
    "    \n",
    "    if sigma_min < 1e-15:\n",
    "        kappa = float('inf')\n",
    "    else:\n",
    "        kappa = sigma_max / sigma_min\n",
    "    \n",
    "    return kappa, S\n",
    "\n",
    "# Well-conditioned matrix\n",
    "A_good = torch.tensor([[1., 0.], [0., 1.]], dtype=torch.float64)  # Identity\n",
    "kappa, S = compute_condition_number(A_good)\n",
    "print(f\"Identity matrix:\")\n",
    "print(f\"  Singular values: {S.tolist()}\")\n",
    "print(f\"  Condition number: {kappa:.2f}\")\n",
    "print(f\"  Status: Well-conditioned ✓\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Ill-conditioned matrix\n",
    "A_bad = torch.tensor([[1., 1.], [1., 1.0001]], dtype=torch.float64)\n",
    "kappa, S = compute_condition_number(A_bad)\n",
    "print(f\"Nearly singular matrix:\")\n",
    "print(f\"  Singular values: {S.tolist()}\")\n",
    "print(f\"  Condition number: {kappa:.0f}\")\n",
    "print(f\"  Status: Ill-conditioned ✗\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Geometric Intuition\n",
    "\n",
    "The condition number describes how much a matrix \"stretches\" space:\n",
    "\n",
    "- $\\sigma_{\\max}$: Maximum stretch\n",
    "- $\\sigma_{\\min}$: Minimum stretch\n",
    "- $\\kappa = \\sigma_{\\max}/\\sigma_{\\min}$: Ratio of stretches\n",
    "\n",
    "A high condition number means the matrix stretches much more in some directions than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how matrices transform the unit circle\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Unit circle\n",
    "theta = np.linspace(0, 2*np.pi, 100)\n",
    "circle = np.array([np.cos(theta), np.sin(theta)])\n",
    "\n",
    "matrices = [\n",
    "    (np.array([[1, 0], [0, 1]]), \"Identity\\nκ = 1\"),\n",
    "    (np.array([[2, 0], [0, 0.5]]), \"Moderate stretch\\nκ = 4\"),\n",
    "    (np.array([[10, 0], [0, 0.1]]), \"Extreme stretch\\nκ = 100\")\n",
    "]\n",
    "\n",
    "for ax, (A, title) in zip(axes, matrices):\n",
    "    # Transform circle\n",
    "    ellipse = A @ circle\n",
    "    \n",
    "    ax.plot(circle[0], circle[1], 'b--', alpha=0.5, label='Unit circle')\n",
    "    ax.plot(ellipse[0], ellipse[1], 'r-', linewidth=2, label='Transformed')\n",
    "    ax.set_xlim(-12, 12)\n",
    "    ax.set_ylim(-12, 12)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.axhline(y=0, color='k', linewidth=0.5)\n",
    "    ax.axvline(x=0, color='k', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Effect on Solution Accuracy\n",
    "\n",
    "With floating-point precision of ~16 digits:\n",
    "\n",
    "| $\\kappa(A)$ | Digits lost | Reliable digits |\n",
    "|-------------|-------------|----------------|\n",
    "| $10^0$ | 0 | 16 |\n",
    "| $10^4$ | 4 | 12 |\n",
    "| $10^8$ | 8 | 8 |\n",
    "| $10^{12}$ | 12 | 4 |\n",
    "| $10^{16}$ | 16 | 0 (garbage) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_condition_effect(kappa_target):\n",
    "    \"\"\"Show how condition number affects solution accuracy.\"\"\"\n",
    "    # Create matrix with specified condition number\n",
    "    n = 10\n",
    "    U, _ = torch.linalg.qr(torch.randn(n, n, dtype=torch.float64))\n",
    "    V, _ = torch.linalg.qr(torch.randn(n, n, dtype=torch.float64))\n",
    "    \n",
    "    # Singular values from 1 to 1/kappa\n",
    "    S = torch.logspace(0, -np.log10(kappa_target), n, dtype=torch.float64)\n",
    "    \n",
    "    A = U @ torch.diag(S) @ V.T\n",
    "    \n",
    "    # True solution\n",
    "    x_true = torch.randn(n, dtype=torch.float64)\n",
    "    b = A @ x_true\n",
    "    \n",
    "    # Solve\n",
    "    x_computed = torch.linalg.solve(A, b)\n",
    "    \n",
    "    # Error\n",
    "    relative_error = torch.norm(x_computed - x_true) / torch.norm(x_true)\n",
    "    \n",
    "    kappa_actual, _ = compute_condition_number(A)\n",
    "    \n",
    "    return kappa_actual, relative_error.item()\n",
    "\n",
    "print(\"Effect of condition number on solution accuracy:\")\n",
    "print(f\"{'κ(A)':<15} {'Relative Error':<20} {'Accurate Digits':<15}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for kappa_target in [1e2, 1e4, 1e6, 1e8, 1e10, 1e12]:\n",
    "    kappa, error = demonstrate_condition_effect(kappa_target)\n",
    "    digits = max(0, -np.log10(error + 1e-16))\n",
    "    print(f\"{kappa:<15.2e} {error:<20.2e} {digits:<15.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. The Squared Condition Number Problem\n",
    "\n",
    "For least squares, the normal equations involve $X^\\top X$:\n",
    "\n",
    "$$\\kappa(X^\\top X) = \\kappa(X)^2$$\n",
    "\n",
    "This is because singular values of $X^\\top X$ are squares of singular values of $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate κ(X'X) = κ(X)²\n",
    "print(\"Condition number squaring:\")\n",
    "print(f\"{'κ(X)':<15} {'κ(X\\'X)':<20} {'κ(X)²':<15} {'Match?':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for kappa_x in [10, 100, 1000, 10000]:\n",
    "    # Create X with known condition number\n",
    "    m, n = 50, 5\n",
    "    U, _ = torch.linalg.qr(torch.randn(m, n, dtype=torch.float64))\n",
    "    V, _ = torch.linalg.qr(torch.randn(n, n, dtype=torch.float64))\n",
    "    S = torch.logspace(0, -np.log10(kappa_x), n, dtype=torch.float64)\n",
    "    X = U @ torch.diag(S) @ V.T\n",
    "    \n",
    "    # Compute condition numbers\n",
    "    kappa_X, _ = compute_condition_number(X)\n",
    "    kappa_XtX, _ = compute_condition_number(X.T @ X)\n",
    "    \n",
    "    match = \"✓\" if abs(kappa_XtX - kappa_X**2) / kappa_X**2 < 0.01 else \"✗\"\n",
    "    print(f\"{kappa_X:<15.0f} {kappa_XtX:<20.0f} {kappa_X**2:<15.0f} {match:<10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Diagnosing Ill-Conditioning in Genomics\n",
    "\n",
    "Common causes of ill-conditioned design matrices:\n",
    "\n",
    "1. **Collinear covariates**: Batch ≈ Treatment\n",
    "2. **Scaling issues**: Covariates on very different scales\n",
    "3. **Imbalanced groups**: 99 controls, 1 treatment\n",
    "4. **Near-redundant columns**: Age and BirthYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnose_design_matrix(X, names=None):\n",
    "    \"\"\"Diagnose potential issues with a design matrix.\"\"\"\n",
    "    m, n = X.shape\n",
    "    \n",
    "    print(f\"Design matrix: {m} samples × {n} covariates\")\n",
    "    \n",
    "    # SVD\n",
    "    U, S, Vh = torch.linalg.svd(X, full_matrices=False)\n",
    "    \n",
    "    # Condition number\n",
    "    kappa = (S[0] / S[-1]).item() if S[-1] > 1e-15 else float('inf')\n",
    "    \n",
    "    print(f\"\\nSingular values: {S.numpy().round(4)}\")\n",
    "    print(f\"Condition number: {kappa:.2e}\")\n",
    "    \n",
    "    # Status\n",
    "    if kappa < 100:\n",
    "        print(\"Status: ✓ Well-conditioned\")\n",
    "    elif kappa < 1e6:\n",
    "        print(\"Status: ⚠️ Moderate - check your design\")\n",
    "    else:\n",
    "        print(\"Status: ✗ Ill-conditioned - results unreliable!\")\n",
    "    \n",
    "    # Check for near-zero singular values\n",
    "    effective_rank = (S > S[0] * 1e-10).sum().item()\n",
    "    if effective_rank < n:\n",
    "        print(f\"\\n⚠️ Effective rank: {effective_rank}/{n}\")\n",
    "        print(\"   Some covariates are nearly collinear!\")\n",
    "    \n",
    "    # Correlation between columns\n",
    "    print(\"\\nColumn correlations (|r| > 0.9 flagged):\")\n",
    "    X_centered = X - X.mean(dim=0)\n",
    "    X_norm = X_centered / (X_centered.norm(dim=0) + 1e-10)\n",
    "    corr = X_norm.T @ X_norm / m\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            r = corr[i, j].item()\n",
    "            if abs(r) > 0.9:\n",
    "                name_i = names[i] if names else f\"Col {i}\"\n",
    "                name_j = names[j] if names else f\"Col {j}\"\n",
    "                print(f\"   ⚠️ {name_i} ↔ {name_j}: r = {r:.3f}\")\n",
    "\n",
    "# Example: Problematic design\n",
    "print(\"Example: Confounded experiment\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Batch perfectly correlated with treatment\n",
    "X_bad = torch.tensor([\n",
    "    [1., 0., 0.],\n",
    "    [1., 0., 0.],\n",
    "    [1., 0., 0.],\n",
    "    [1., 1., 1.],  # Treatment = Batch!\n",
    "    [1., 1., 1.],\n",
    "    [1., 1., 1.],\n",
    "], dtype=torch.float64)\n",
    "\n",
    "diagnose_design_matrix(X_bad, names=['Intercept', 'Treatment', 'Batch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good design: Treatment and Batch not confounded\n",
    "print(\"\\nExample: Proper experimental design\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "X_good = torch.tensor([\n",
    "    [1., 0., 0.],  # Control, Batch A\n",
    "    [1., 0., 0.],\n",
    "    [1., 1., 0.],  # Treatment, Batch A\n",
    "    [1., 1., 0.],\n",
    "    [1., 0., 1.],  # Control, Batch B\n",
    "    [1., 0., 1.],\n",
    "    [1., 1., 1.],  # Treatment, Batch B\n",
    "    [1., 1., 1.],\n",
    "], dtype=torch.float64)\n",
    "\n",
    "diagnose_design_matrix(X_good, names=['Intercept', 'Treatment', 'Batch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Rules of Thumb\n",
    "\n",
    "| $\\kappa(A)$ | Status | Action |\n",
    "|-------------|--------|--------|\n",
    "| $< 100$ | ✓ Good | Proceed normally |\n",
    "| $100 - 10^6$ | ⚠️ Moderate | Check design, consider centering/scaling |\n",
    "| $> 10^6$ | ✗ Bad | Regularization required |\n",
    "| $> 10^{12}$ | ✗✗ Very bad | Redesign experiment or model |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: Compute Condition Numbers\n",
    "Create matrices with condition numbers of approximately 10, 1000, and 1000000. Verify with SVD.\n",
    "\n",
    "### Exercise 2: Scaling Effect\n",
    "Create a design matrix where one column is Age (20-80) and another is Gene Expression (0.001-0.01). Check condition number before and after standardizing.\n",
    "\n",
    "### Exercise 3: Real Design Matrix\n",
    "Simulate a design matrix for: 50 samples, 2 batches, 2 treatments, 2 sexes (balanced design). Check if it's well-conditioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solutions here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Concept | Key Point |\n",
    "|---------|----------|\n",
    "| Condition number | $\\kappa(A) = \\sigma_{\\max}/\\sigma_{\\min}$ |\n",
    "| Well-conditioned | $\\kappa \\approx 1$, stable solutions |\n",
    "| Ill-conditioned | $\\kappa \\gg 1$, unreliable solutions |\n",
    "| Squaring problem | $\\kappa(X^\\top X) = \\kappa(X)^2$ |\n",
    "| Solution | Use QR instead of normal equations |\n",
    "\n",
    "## Next: 03_qr_decomposition.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
